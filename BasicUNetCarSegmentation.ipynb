{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic UNet Example\n",
    "\n",
    "Based on:\n",
    "https://github.com/overshiki/unet-pytorch/blob/master/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do\n",
    "\n",
    " * Clean up the plots to provide proper axes labels etc (make it look pretty!)\n",
    " * Data augmentation (but carefully as the mask needs to be done too)\n",
    " * Early stopping criterion\n",
    " * Validation in the epoch loop\n",
    " * Train / validation / test split and test at end of epochs\n",
    " * Different hyperparameters (what is the \"best\" learning rate, what is the \"best\" optimizer)?\n",
    " * How could you get more accurate masks? (In particular the finer detail)\n",
    " * How much slower is it on a CPU rather than a GPU?\n",
    " * How many datasets are required for \"accurate\" results?  (What is an \"accurate\" result)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets,transforms, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# GPU CPU - nice way to setup the device as it works on any machine\n",
    "#\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f'Device is {device}')\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f'CUDA device {torch.cuda.device(0)}')\n",
    "    print(f'Number of devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "    \n",
    "                                # converts 0-255 to 0-1 and rowxcolxchan to chanxrowxcol\n",
    "                                transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, zip_filename_cars, zip_filename_masks, transform):\n",
    "        \"\"\"\n",
    "        Initialized\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store variables we are interested in...\n",
    "        \n",
    "        self._zip_filename_cars = zip_filename_cars\n",
    "        self._zip_filename_masks = zip_filename_masks\n",
    "        \n",
    "        self._zip_filename_cars_zf = zipfile.ZipFile(self._zip_filename_cars, \"r\")\n",
    "        self._zip_filename_masks_zf = zipfile.ZipFile(self._zip_filename_masks, \"r\")\n",
    "        \n",
    "        self._transforms = transform        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a single image / label pair.\n",
    "        \"\"\"\n",
    "        \n",
    "        #\n",
    "        # Read in the image\n",
    "        #\n",
    "        name = self._zip_filename_cars_zf.namelist()[index+1]\n",
    "        image = Image.open(BytesIO(self._zip_filename_cars_zf.read(name)))\n",
    "        \n",
    "        #\n",
    "        # Read in the mask\n",
    "        #\n",
    "        name = name.replace('train/', 'train_masks/').replace('.jpg', '_mask.gif')\n",
    "        mask = Image.open(BytesIO(self._zip_filename_masks_zf.read(name)))\n",
    "        \n",
    "        #\n",
    "        #  Can do further processing here or anything else\n",
    "        #\n",
    "        \n",
    "        # image = clahe(image)\n",
    "        \n",
    "        #\n",
    "        # Do transformations on it (typicalyl data augmentation)\n",
    "        #\n",
    "        if self._transforms is not None:\n",
    "            image = self._transforms(image)\n",
    "            mask = self._transforms(mask)\n",
    "                \n",
    "        #\n",
    "        # Return the image mask pair\n",
    "        #\n",
    "        return image, mask[0]>0\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self._zip_filename_cars_zf.namelist())-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CarDataset('train.zip', 'train_masks.zip', transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show an Example (for Sanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = train_dataset[2]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.array(image).transpose((1,2,0)))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.array(mask).squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contracting(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 64, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(128, 256, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(256, 512, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(512, 1024, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(1024, 1024, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.down_sample = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X1 = self.layer1(X)\n",
    "        X2 = self.layer2(self.down_sample(X1))\n",
    "        X3 = self.layer3(self.down_sample(X2))\n",
    "        X4 = self.layer4(self.down_sample(X3))\n",
    "        X5 = self.layer5(self.down_sample(X4))\n",
    "        return X5, X4, X3, X2, X1\n",
    "\n",
    "\n",
    "class expansive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Conv2d(64, 2, 3, stride=1, padding=1)\n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(256, 128, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(512, 256, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(1024, 512, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU())\n",
    "\n",
    "        self.up_sample_54 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "\n",
    "        self.up_sample_43 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "\n",
    "        self.up_sample_32 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "\n",
    "        self.up_sample_21 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, X5, X4, X3, X2, X1):\n",
    "        X = self.up_sample_54(X5)\n",
    "        X4 = torch.cat([X, X4], dim=1)\n",
    "        X4 = self.layer5(X4)\n",
    "\n",
    "        X = self.up_sample_43(X4)\n",
    "        X3 = torch.cat([X, X3], dim=1)\n",
    "        X3 = self.layer4(X3)\n",
    "\n",
    "        X = self.up_sample_32(X3)\n",
    "        X2 = torch.cat([X, X2], dim=1)\n",
    "        X2 = self.layer3(X2)\n",
    "\n",
    "        X = self.up_sample_21(X2)\n",
    "        X1 = torch.cat([X, X1], dim=1)\n",
    "        X1 = self.layer2(X1)\n",
    "\n",
    "        X = self.layer1(X1)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.down = contracting()\n",
    "        \n",
    "        # Decoder\n",
    "        self.up = expansive()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Encoder\n",
    "        X5, X4, X3, X2, X1 = self.down(X)\n",
    "        \n",
    "        # Decoder\n",
    "        X = self.up(X5, X4, X3, X2, X1)\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('='*30)\n",
    "    print('Epoch {} / {}'.format(epoch, epochs))\n",
    "    \n",
    "    # Set variables\n",
    "    correct = 0\n",
    "    overlap = 0 \n",
    "    union = 0\n",
    "    _len = 0\n",
    "    l = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Loop over the batches\n",
    "    for index, (X, Y) in enumerate(train_dataloader):\n",
    "        print(f'\\tBatch {index}')\n",
    "        \n",
    "        if device is not None:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "        # Call the model (image to mask)\n",
    "        R = model(X)\n",
    "\n",
    "        # Compute the loss\n",
    "        # L = loss(R[:,0], Y[:,0].long())\n",
    "        L = loss(R, Y.long())\n",
    "\n",
    "        # Do PyTorch stuff\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute Stats\n",
    "        pred = R.data.max(1)[1]\n",
    "        pred_sum, label_sum, overlap_sum = (pred==1).sum(), (Y==1).sum(), (pred*Y==1).sum()\n",
    "        print(f'\\t label_sum {label_sum}  pred_sum {pred_sum}  overlap_sum {overlap_sum}')\n",
    "        \n",
    "#         plt.figure(1)\n",
    "#         plt.subplot(1,2,1)\n",
    "#         plt.imshow(Y[0].cpu())\n",
    "#         plt.clim((0,1))\n",
    "#         plt.subplot(1,2,2)\n",
    "#         plt.imshow(pred[0].cpu())\n",
    "#         plt.clim((0,1))\n",
    "#         plt.show()\n",
    "\n",
    "        union_sum = pred_sum+label_sum-overlap_sum\n",
    "\n",
    "        # IoU for accuracy\n",
    "        overlap = overlap+overlap_sum.data.item()\n",
    "        union = union+union_sum.data.item()\n",
    "        l = l+L.data.item()\n",
    "        count = count+1\n",
    "\n",
    "    _loss = l/count\n",
    "    _accuracy = overlap/union\n",
    "    string = \"epoch: {}, accuracy: {}, loss: {}\".format(epoch, _accuracy, _loss)\n",
    "    print(string)\n",
    "    \n",
    "    epoch_loss.append(_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epoch_loss)\n",
    "plt.title('Epoch Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot an Example Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Y[3].cpu())\n",
    "plt.clim((0,1))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pred[3].cpu())\n",
    "plt.clim((0,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
